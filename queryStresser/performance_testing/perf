#!/bin/bash
BASEDIR=$(dirname $0)
CONF_DIR="configs"
DATA_DIR="dataset"
RESULT_DIR="results"
JAR_FILE="../target/queryStresser-1.0-jar-with-dependencies.jar"
NBQUERY=100000

function createJSON {
    rm -f "$CONF_DIR"/*.json
    local MEANS=("0" "50000")
    local STDDEV=("10" "1000" "10000")

    LENMEANS=${#MEANS[@]}
    LENSTD=${#STDDEV[@]}
    for (( i=0; i<${LENMEANS}; i++ )); do
        for (( j=0; j<${LENSTD}; j++ )); do
            echo "{
    \"filename\": \"$DATA_DIR/normal${MEANS[$i]}_${STDDEV[$j]}\",
    \"nbOut\": $NBQUERY,
    \"queryFile\": \"querySample.txt\",
    \"nbQueries\": 100000,
    \"uniform\": false,
    \"gaussian\": {
        \"mean\": ${MEANS[$i]},
        \"stddev\": ${STDDEV[$j]}
    }
}" > "$CONF_DIR"/normal"${MEANS[$i]}"_"${STDDEV[$j]}".json
        done
    done

    # We do for uniform
    echo "{
    \"filename\": \"$DATA_DIR/uniform\",
    \"nbOut\": $NBQUERY,
    \"queryFile\": \"querySample.txt\",
    \"nbQueries\": 100000,
    \"uniform\": true,
    \"gaussian\": {
        \"mean\": 0,
        \"stddev\": 0
    }
}" > "$CONF_DIR"/uniform.json
}

function generateData {
    rm -f "$DATA_DIR"/*.csv
    for i in "$CONF_DIR"/*.json; do
        java -jar "$JAR_FILE" "$i" 
    done
}

function analyze {
    rm -f "$RESULT_DIR"/*
    for file in "$DATA_DIR"/*.csv; do 
        echo $file
        jmeter/bin/jmeter -n -t loadTest.jmx -Jfile.name=$(basename "$file") -Jpath.data=$(pwd)/"$DATA_DIR" -Jpath.result=$(pwd)/"$RESULT_DIR"
    done
}

function observe {
    jmeter/bin/jmeter -t loadTest.jmx -Jfile.name="none" -Jpath.data=$(pwd)/"$DATA_DIR" -Jpath.result=$(pwd)/"$RESULT_DIR"
}

function usage {
    echo "usage $1:This script aims to simplify the generation of dataset/results for clucene's search part there are different possible commands:
    - -d <number of queries> generates a dataset using clucene's queryStresser module in that case you can provide a second integer argument to specify the number of queries will be contain in each file.
    - -e uses jmeter and Loadosophia plugin to evaluate the performance of a clucene cluster when searching on it. it creates all the result files in the results folder
    - -o <name of the dataset> opens jmeter with the specified dataset's results to observe the results
"
}

d=off
e=off
o=off
if [ $# -eq 0 ]; then
    usage $0
fi

while [ $# -gt 0 ]
do
    case "$1" in
        -d)
            d=on
            NBQUERY="$2"; 
            shift;;
        -e)
            e=on;;
        -o)
            o=on
            shift;;
        --) shift; break;;
        -*)
            usage $0
            exit 1;;
        *)  break;;
    esac
    shift
done

if [ $d == "on" ]; then
    echo "dataset"
    createJSON
    generateData
fi

if [ $e == "on" ]; then
    echo "evaluate"
    analyze
fi

if [ $o == "on" ]; then
    echo "observe"
    observe
fi
